{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\", device_map = 'mps')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa63030",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../self_contra/wino_bias_question_similarity/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path)\n",
    "if '.DS_Store' in files:\n",
    "    files.remove('.DS_Store')\n",
    "len(files), files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aae156",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.remove('pro_stereotyped_type1.txt.dev.csv')\n",
    "files.remove('anti_stereotyped_type2.txt.dev.csv')\n",
    "files.remove('anti_stereotyped_type1.txt.dev.csv')\n",
    "files.remove('anti_stereotyped_type1.txt.test.csv')\n",
    "files.remove('pro_stereotyped_type2.txt.test.csv')\n",
    "files.remove('pro_stereotyped_type2.txt.dev.csv')\n",
    "files.remove('anti_stereotyped_type2.txt.test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=['anti_stereotyped_type2.txt.dev.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mistral_pred(question): \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":f\"\"\"Question: {question} \n",
    "            Give your reason first, then answer, answer should be in maximum 3 to 4 words. \n",
    "            Follow the format: reason:[reason]:\\nAnswer:[Answer]\\n\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    model_inputs = tokenizer.apply_chat_template(messages, return_tensors = \"pt\").to('mps')\n",
    "    pad_token_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "    attention_mask = model_inputs.ne(pad_token_id).long()\n",
    "\n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens = 1000, do_sample = True, \n",
    "                                   attention_mask=attention_mask, pad_token_id=pad_token_id)\n",
    "    output = tokenizer.batch_decode(generated_ids, skip_special_tokens = True)[0]\n",
    "    #print(output)\n",
    "    if 'Answer:[Answer]' in output:\n",
    "        index = output.index('Answer:[Answer]')\n",
    "        a = output[index+25:]\n",
    "        b = a.index('Answer')\n",
    "        \n",
    "        reason = a[:b]\n",
    "        result = a[b+8:]\n",
    "        \n",
    "        return reason, result\n",
    "    return None, None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, file_name in enumerate(files):    \n",
    "    pred = []\n",
    "    reasons = []\n",
    "    \n",
    "    real_questions = []\n",
    "    real_ground_truths = []\n",
    "    real_reasonings = []\n",
    "    real_predictions = [] \n",
    "    real_generated_questionss = []\n",
    "    real_similarity_values = []\n",
    "    real_question_nums = []\n",
    "    df = pd.DataFrame(columns = ['question', 'ground_truth', 'reasoning', 'prediction', 'generated_questions', 'similarity_value', 'question_num', 'reason_for_generated', 'pred_for_generated'])\n",
    "\n",
    "    data = pd.read_csv(path + file_name)\n",
    "    for i, row in data.iterrows(): \n",
    "        if i < 363:\n",
    "            continue\n",
    "        print(num, file_name, i)\n",
    "        real_question = row['question']\n",
    "        real_ground_truth = row['ground_truth']\n",
    "        real_reasoning = row['reasoning']\n",
    "        real_prediction = row['prediction']\n",
    "        real_generated_questions = row['generated_questions']\n",
    "        real_similarity_value = row['similarity_value']\n",
    "        real_question_num = row['question_num']\n",
    "        \n",
    "        line = str(row['question'])\n",
    "        question = line.split('.')[0]\n",
    "        question_num = row['question_num']\n",
    "        generated_questions = row['generated_questions']\n",
    "        generated_questions = ast.literal_eval(generated_questions)\n",
    "        if question_num == 0:\n",
    "            q = generated_questions['question1']\n",
    "            question += q\n",
    "            reason, result = get_mistral_pred(question)\n",
    "        elif question_num == 1:\n",
    "            q = generated_questions['question2']\n",
    "            question += q\n",
    "            reason, result = get_mistral_pred(question)\n",
    "        elif question_num == 2:\n",
    "            q = generated_questions['question3']\n",
    "            question += q\n",
    "            reason, result = get_mistral_pred(question)\n",
    "        else:\n",
    "            reason, result = None, None\n",
    "        \n",
    "        \n",
    "        reason, result = get_mistral_pred(question)\n",
    "        reasons.append(reason)\n",
    "        pred.append(result)\n",
    "        \n",
    "        real_questions.append(real_question) \n",
    "        real_ground_truths.append(real_ground_truth)\n",
    "        real_reasonings.append(real_reasoning) \n",
    "        real_predictions.append(real_prediction) \n",
    "        real_generated_questionss.append(generated_questions)\n",
    "        real_similarity_values.append(real_similarity_value)\n",
    "        real_question_nums.append(real_question_num)\n",
    "        \n",
    "        \n",
    "    \n",
    "    df['reason_for_generated'] = reasons\n",
    "    df['pred_for_generated'] = pred\n",
    "    \n",
    "    df['question'] = real_questions\n",
    "    df['ground_truth'] = real_ground_truths\n",
    "    df['reasoning'] = real_reasonings\n",
    "    df['prediction'] = real_predictions\n",
    "    df['generated_questions'] = real_generated_questionss\n",
    "    df['similarity_value'] = real_similarity_values\n",
    "    df['question_num'] = real_question_nums\n",
    "    df.to_csv('../self_contra/wino_bias_reason_answer_for_generated_question_by_mistral/' + file_name + '3.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c78484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reason_for_generated'] = reasons\n",
    "df['pred_for_generated'] = pred\n",
    "\n",
    "df['question'] = real_questions\n",
    "df['ground_truth'] = real_ground_truths\n",
    "df['reasoning'] = real_reasonings\n",
    "df['prediction'] = real_predictions\n",
    "df['generated_questions'] = real_generated_questionss\n",
    "df['similarity_value'] = real_similarity_values\n",
    "df['question_num'] = real_question_nums\n",
    "df.to_csv('../self_contra/wino_bias_reason_answer_for_generated_question_by_mistral/' + file_name + '2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28dc963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
