{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9553330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-genai pillow\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_api_key = \"\"\n",
    "gemini_api_key = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ea1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '../Tell2Design Data/centroid_distance/'\n",
    "path2 = '../Tell2Design Data/direct_adjacency/'\n",
    "path3 = '../Tell2Design Data/room_removal/'\n",
    "path4 = '../Tell2Design Data/common_neighbor/'\n",
    "path5 = '../Tell2Design Data/topological_ordering/'\n",
    "path6 = '../Tell2Design Data/gemini_description_latest/'\n",
    "\n",
    "save_path_4 = '../Tell2Design Data/images/centroid_adjacent_removal_neighbor/'\n",
    "save_path_4_topo = '../Tell2Design Data/images/centroid_adjacent_removal_neighbor_topology/'\n",
    "save_path_topo = '../Tell2Design Data/images/topological/'\n",
    "save_path_desc = '../Tell2Design Data/images/description/'\n",
    "\n",
    "save_path_4_json = '../Tell2Design Data/images/centroid_adjacent_removal_neighbor_json/'\n",
    "save_path_desc_json = '../Tell2Design Data/images/description_json/'\n",
    "save_path_topo_json = '../Tell2Design Data/images/topological_json/'\n",
    "save_path_4_topo_json = '../Tell2Design Data/images/centroid_adjacent_removal_neighbor_topology_json/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4564a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(path1)\n",
    "if '.DS_Store' in files:\n",
    "    files.remove('.DS_Store')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_gpt(text, path):\n",
    "    url = \"https://api.openai.com/v1/images/generations\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {gpt_api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-image-1\",\n",
    "        \"prompt\": text,\n",
    "        \"size\": \"auto\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "    #if response.status_code == 200:\n",
    "    image_base64 = response.json()[\"data\"][0][\"b64_json\"]\n",
    "    image_bytes = base64.b64decode(image_base64)\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(image_bytes)\n",
    "        \n",
    "    #else:\n",
    "    #    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_gemini_imagen(path: str, gemini_api_key: str, prompt: str, out_prefix: str = \"imagen\"):\n",
    "    client = genai.Client(api_key=\"\")\n",
    "    response = client.models.generate_images(\n",
    "        model='imagen-4.0-generate-001',\n",
    "        prompt=prompt,\n",
    "        config=types.GenerateImagesConfig(\n",
    "            number_of_images= 1,\n",
    "        )\n",
    "    )\n",
    "    for generated_image in response.generated_images:\n",
    "        img_bytes = base64.b64decode(generated_image.image.image_bytes)\n",
    "        img = Image.open(BytesIO(img_bytes))\n",
    "        img.save(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concise_text(data, gpt_api_key):\n",
    "    prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "                \"You are an expert at condensing step-by-step spatial reasoning into a compact but complete set of facts for floor plan generation.\"\n",
    "                \"You are given reasoning traces from multiple queries. Your goal is to remove redundant statements while keeping all unique and essential details.\"\n",
    "                \"Preserve:\"\n",
    "                \" - Exact room names as given.\"\n",
    "                \" - Exact RGB color values for each room, exactly as written in the reasoning.\"\n",
    "                \" - Positive relations (e.g., “Room X is adjacent to Room Y”, “Room X is north of Room Y”, “Room X is present”).\"\n",
    "                \" - Negative relations (e.g., “Room X is not adjacent to Room Y”, “Room X is absent”).\"\n",
    "                \" - Positions, directions, and connectivity information.\"\n",
    "                \" - Topological ordering if given.\"\n",
    "                \" - Room counts and relative sizes.\"\n",
    "                \"Do not add new facts or change the meaning of the original reasoning.\"\n",
    "                \"Output as a single concise text that contains only factual information needed to recreate the floor plan.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"Reasoning: {data}\\n\"\n",
    "            \"Return:\\n\"\n",
    "            \"summary: ...\"\n",
    "        )\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    payload = {\n",
    "                    \"model\": \"gpt-3.5-turbo\",\n",
    "                    \"messages\": prompt,\n",
    "                    \"max_tokens\": 2000,\n",
    "                    \"temperature\": 0.2\n",
    "                }\n",
    "    headers = {\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"Authorization\": f\"Bearer {gpt_api_key}\"\n",
    "                }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    output = response.json()['choices'][0]['message']['content']\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_i, file_name in enumerate(files):\n",
    "    print(file_i)\n",
    "    if file_i < 911:\n",
    "        continue\n",
    "    file1 = path1 + file_name\n",
    "    file2 = path2 + file_name\n",
    "    file3 = path3 + file_name\n",
    "    file4 = path4 + file_name\n",
    "    file5 = path5 + file_name\n",
    "    file6 = path6 + file_name\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with open(file1, 'r') as f:\n",
    "        data1 = json.load(f)\n",
    "        reason1 = data1['Reason']\n",
    "        data.extend(reason1)\n",
    "    \n",
    "    with open(file2, 'r') as f:\n",
    "        data2 = json.load(f)\n",
    "        reason2 = data2['Reason']\n",
    "        data.extend(reason2)\n",
    "    with open(file3, 'r') as f:\n",
    "        data3 = json.load(f)\n",
    "        reason3 = data3['Reason']\n",
    "        data.extend(reason3)\n",
    "    with open(file4, 'r') as f:\n",
    "        data4 = json.load(f)\n",
    "        reason4 = data4['Reason']\n",
    "        data.extend(reason4)\n",
    "    with open(file5, 'r') as f:\n",
    "        data5 = json.load(f)\n",
    "        reason5 = data5['Reason']\n",
    "        data.extend(reason5)\n",
    "    '''\n",
    "    with open(file6, 'r') as f:\n",
    "        data6 = json.load(f)\n",
    "        reason6 = data6['Reason']\n",
    "        data.extend(reason6)\n",
    "    '''\n",
    "    text = ' '.join(data)\n",
    "    path = save_path_4_topo + file_name.split('.json')[0] + '.png'\n",
    "    concise_text = generate_concise_text(text, gpt_api_key)\n",
    "    result = {\n",
    "        'concise_text':concise_text\n",
    "    }\n",
    "    json_path = save_path_4_topo_json + file_name\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(result, f, indent = 2)\n",
    "    concise_text = \"Generate a floor map based on the following context: show the entrance in a small, specified color mentioned only in the text line. \"  + concise_text\n",
    "    #generate_image_gemini_imagen(gemini_api_key, concise_text)\n",
    "    generate_image_gpt(concise_text, path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f76fbba",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
